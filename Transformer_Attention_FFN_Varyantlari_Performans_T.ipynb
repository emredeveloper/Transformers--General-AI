{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30887,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emredeveloper/Transformers--General-AI/blob/main/Transformer_Attention_FFN_Varyantlari_Performans_T.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright (c) Sebastian Raschka under Apache License 2.0 (see LICENSE.txt).\n",
        "# Source for \"Build a Large Language Model From Scratch\"\n",
        "#   - https://www.manning.com/books/build-a-large-language-model-from-scratch\n",
        "# Code: https://github.com/rasbt/LLMs-from-scratch\n",
        "\n",
        "# This file collects all the relevant code that we covered thus far\n",
        "# throughout Chapters 2-4.\n",
        "# This file can be run as a standalone script.\n",
        "\n",
        "import tiktoken\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "#####################################\n",
        "# Chapter 2\n",
        "#####################################\n",
        "\n",
        "class GPTDatasetV1(Dataset):\n",
        "    def __init__(self, txt, tokenizer, max_length, stride):\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "\n",
        "        # Tokenize the entire text\n",
        "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
        "        for i in range(0, len(token_ids) - max_length, stride):\n",
        "            input_chunk = token_ids[i:i + max_length]\n",
        "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
        "            self.input_ids.append(torch.tensor(input_chunk))\n",
        "            self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx]\n",
        "\n",
        "\n",
        "def create_dataloader_v1(txt, batch_size=4, max_length=256,\n",
        "                         stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
        "    # Initialize the tokenizer\n",
        "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "    # Create dataset\n",
        "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
        "\n",
        "    # Create dataloader\n",
        "    dataloader = DataLoader(\n",
        "        dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last, num_workers=num_workers)\n",
        "\n",
        "    return dataloader\n",
        "\n",
        "\n",
        "#####################################\n",
        "# Chapter 3\n",
        "#####################################\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        assert d_out % num_heads == 0, \"d_out must be divisible by n_heads\"\n",
        "\n",
        "        self.d_out = d_out\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads  # Reduce the projection dim to match desired output dim\n",
        "\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, num_tokens, d_in = x.shape\n",
        "\n",
        "        keys = self.W_key(x)  # Shape: (b, num_tokens, d_out)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
        "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
        "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
        "        keys = keys.transpose(1, 2)\n",
        "        queries = queries.transpose(1, 2)\n",
        "        values = values.transpose(1, 2)\n",
        "\n",
        "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
        "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
        "\n",
        "        # Original mask truncated to the number of tokens and converted to boolean\n",
        "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "\n",
        "        # Use the mask to fill attention scores\n",
        "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
        "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
        "\n",
        "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
        "        context_vec = context_vec.reshape(b, num_tokens, self.d_out)\n",
        "        context_vec = self.out_proj(context_vec)  # optional projection\n",
        "\n",
        "        return context_vec\n",
        "\n",
        "\n",
        "#####################################\n",
        "# Chapter 4\n",
        "#####################################\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, emb_dim):\n",
        "        super().__init__()\n",
        "        self.eps = 1e-5\n",
        "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
        "        return self.scale * norm_x + self.shift\n",
        "\n",
        "\n",
        "class GELU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1 + torch.tanh(\n",
        "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
        "            (x + 0.044715 * torch.pow(x, 3))\n",
        "        ))\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
        "            GELU(),\n",
        "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.att = MultiHeadAttention(\n",
        "            d_in=cfg[\"emb_dim\"],\n",
        "            d_out=cfg[\"emb_dim\"],\n",
        "            context_length=cfg[\"context_length\"],\n",
        "            num_heads=cfg[\"n_heads\"],\n",
        "            dropout=cfg[\"drop_rate\"],\n",
        "            qkv_bias=cfg[\"qkv_bias\"])\n",
        "        self.ff = FeedForward(cfg)\n",
        "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Shortcut connection for attention block\n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "        x = self.att(x)   # Shape [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut  # Add the original input back\n",
        "\n",
        "        # Shortcut connection for feed-forward block\n",
        "        shortcut = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.ff(x)\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut  # Add the original input back\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class GPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "\n",
        "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits\n",
        "\n",
        "\n",
        "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
        "    # idx is (B, T) array of indices in the current context\n",
        "    for _ in range(max_new_tokens):\n",
        "\n",
        "        # Crop current context if it exceeds the supported context size\n",
        "        # E.g., if LLM supports only 5 tokens, and the context size is 10\n",
        "        # then only the last 5 tokens are used as context\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "\n",
        "        # Get the predictions\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "\n",
        "        # Focus only on the last time step\n",
        "        # (batch, n_token, vocab_size) becomes (batch, vocab_size)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        # Get the idx of the vocab entry with the highest logits value\n",
        "        idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch, 1)\n",
        "\n",
        "        # Append sampled index to the running sequence\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
        "\n",
        "    return idx\n",
        "\n",
        "\n",
        "#####################################\n",
        "# Chapter 5\n",
        "####################################\n",
        "\n",
        "\n",
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "    logits = model(input_batch)\n",
        "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
        "    return loss\n",
        "\n",
        "\n",
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "    total_loss = 0.\n",
        "    if len(data_loader) == 0:\n",
        "        return float(\"nan\")\n",
        "    elif num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            total_loss += loss.item()\n",
        "        else:\n",
        "            break\n",
        "    return total_loss / num_batches\n",
        "\n",
        "\n",
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "    model.train()\n",
        "    return train_loss, val_loss\n",
        "\n",
        "\n",
        "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
        "    model.eval()\n",
        "    context_size = model.pos_emb.weight.shape[0]\n",
        "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
        "    with torch.no_grad():\n",
        "        token_ids = generate_text_simple(\n",
        "            model=model, idx=encoded,\n",
        "            max_new_tokens=50, context_size=context_size)\n",
        "        decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
        "        print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
        "    model.train()\n",
        "\n",
        "\n",
        "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
        "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "\n",
        "    # Plot training and validation loss against epochs\n",
        "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
        "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(\"Loss\")\n",
        "    ax1.legend(loc=\"upper right\")\n",
        "\n",
        "    # Create a second x-axis for tokens seen\n",
        "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
        "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
        "    ax2.set_xlabel(\"Tokens seen\")\n",
        "\n",
        "    fig.tight_layout()  # Adjust layout to make room\n",
        "    # plt.show()\n",
        "\n",
        "\n",
        "def text_to_token_ids(text, tokenizer):\n",
        "    encoded = tokenizer.encode(text)\n",
        "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)  # add batch dimension\n",
        "    return encoded_tensor\n",
        "\n",
        "\n",
        "def token_ids_to_text(token_ids, tokenizer):\n",
        "    flat = token_ids.squeeze(0)  # remove batch dimension\n",
        "    return tokenizer.decode(flat.tolist())\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-12T22:03:47.011719Z",
          "iopub.execute_input": "2025-02-12T22:03:47.01204Z",
          "iopub.status.idle": "2025-02-12T22:03:47.049181Z",
          "shell.execute_reply.started": "2025-02-12T22:03:47.012016Z",
          "shell.execute_reply": "2025-02-12T22:03:47.0478Z"
        },
        "id": "ML-KCXoIw_I0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "#####################################\n",
        "# Ayarlar ve Veri Hazırlığı\n",
        "#####################################\n",
        "\n",
        "def load_data():\n",
        "    # Demo amaçlı küçük bir metin. Gerçek uygulamada daha büyük bir corpus kullanılmalı.\n",
        "    text = (\"Once upon a time, in a land far, far away, there was a kingdom where magic was common \"\n",
        "            \"and adventure awaited around every corner. \") * 100  # metni tekrarlayarak uzunluyoruz\n",
        "    return text\n",
        "\n",
        "def prepare_dataloaders(text, batch_size=4, max_length=128, stride=64):\n",
        "    # Eğitim ve doğrulama için veriyi bölelim (örneğin, %90 eğitim, %10 doğrulama)\n",
        "    split_idx = int(0.9 * len(text))\n",
        "    train_text = text[:split_idx]\n",
        "    val_text = text[split_idx:]\n",
        "    train_loader = create_dataloader_v1(train_text, batch_size=batch_size,\n",
        "                                        max_length=max_length, stride=stride)\n",
        "    val_loader = create_dataloader_v1(val_text, batch_size=batch_size,\n",
        "                                      max_length=max_length, stride=stride)\n",
        "    return train_loader, val_loader\n",
        "\n",
        "#####################################\n",
        "# Model Eğitimi\n",
        "#####################################\n",
        "\n",
        "def train_model(model, train_loader, val_loader, device, epochs=5, eval_iter=10):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=3e-4)\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        epoch_loss = 0.0\n",
        "        start_time = time.time()\n",
        "\n",
        "        for batch_idx, (input_batch, target_batch) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            if (batch_idx + 1) % 10 == 0:\n",
        "                print(f\"Epoch {epoch+1} Batch {batch_idx+1}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "        avg_loss = epoch_loss / len(train_loader)\n",
        "        elapsed = time.time() - start_time\n",
        "        print(f\"Epoch {epoch+1} tamamlandı (süre: {elapsed:.2f}s), ort. loss: {avg_loss:.4f}\")\n",
        "\n",
        "        # Kısa bir değerlendirme: eğitim ve doğrulama loss değerlerini hesapla\n",
        "        train_loss, val_loss = evaluate_model(model, train_loader, val_loader, device, eval_iter)\n",
        "        print(f\"Epoch {epoch+1} değerlendirme: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\\n\")\n",
        "\n",
        "#####################################\n",
        "# Metin Üretimi\n",
        "#####################################\n",
        "\n",
        "def generate_sample(model, tokenizer, device, prompt, max_new_tokens=50):\n",
        "    print(\"Üretilen metin örneği:\\n\")\n",
        "    generate_and_print_sample(model, tokenizer, device, prompt)\n",
        "\n",
        "#####################################\n",
        "# Ana Fonksiyon\n",
        "#####################################\n",
        "\n",
        "def main():\n",
        "    # Cihaz seçimi (GPU varsa kullanılır)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Kullanılan cihaz: {device}\")\n",
        "\n",
        "    # Veri hazırlığı\n",
        "    text = load_data()\n",
        "    train_loader, val_loader = prepare_dataloaders(text, batch_size=4, max_length=128, stride=64)\n",
        "\n",
        "    # Tokenizer ve model konfigürasyonu\n",
        "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "    cfg = {\n",
        "        \"vocab_size\": tokenizer.n_vocab,  # Tokenizer'ın sözlüğündeki kelime sayısı\n",
        "        \"emb_dim\": 128,                   # Küçük bir embedding boyutu (demo amaçlı)\n",
        "        \"context_length\": 128,            # Maksimum dizi uzunluğu\n",
        "        \"drop_rate\": 0.1,\n",
        "        \"n_layers\": 8,                    # Katman sayısı\n",
        "        \"n_heads\": 4,                     # Çoklu başlık sayısı (emb_dim'in tam böleni olmalı)\n",
        "        \"qkv_bias\": True,\n",
        "    }\n",
        "\n",
        "    # Model oluşturulması\n",
        "    model = GPTModel(cfg)\n",
        "\n",
        "    # Modelin eğitimi\n",
        "    train_model(model, train_loader, val_loader, device, epochs=5, eval_iter=10)\n",
        "\n",
        "    # Eğitim bittikten sonra, bir başlangıç prompt'u ile metin üretimi yapalım\n",
        "    prompt = \"Once upon a time \"\n",
        "    generate_sample(model, tokenizer, device, prompt, max_new_tokens=50)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-12T18:01:02.043298Z",
          "iopub.execute_input": "2025-02-12T18:01:02.043586Z",
          "iopub.status.idle": "2025-02-12T18:01:04.598147Z",
          "shell.execute_reply.started": "2025-02-12T18:01:02.043567Z",
          "shell.execute_reply": "2025-02-12T18:01:04.597344Z"
        },
        "id": "DEJyddCuw_I3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import tiktoken\n",
        "from datasets import load_dataset  # Hugging Face datasets library\n",
        "import re\n",
        "\n",
        "#####################################\n",
        "# Rotary Positional Embeddings (ROPE) Implementation\n",
        "#####################################\n",
        "def apply_rotary_pos_emb(x):\n",
        "    \"\"\"\n",
        "    Apply Rotary Positional Embeddings (ROPE) to the input tensor.\n",
        "\n",
        "    Args:\n",
        "        x (torch.Tensor): Input tensor of shape (batch, num_heads, seq_len, head_dim).\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Tensor with ROPE applied.\n",
        "    \"\"\"\n",
        "    batch, n_heads, seq_len, head_dim = x.shape\n",
        "    assert head_dim % 2 == 0, \"head_dim must be even for ROPE\"\n",
        "\n",
        "    # Calculate inverse frequencies and positions\n",
        "    inv_freq = 1.0 / (10000 ** (torch.arange(0, head_dim, 2, device=x.device).float() / head_dim))\n",
        "    positions = torch.arange(seq_len, device=x.device).float()\n",
        "    sinusoid_inp = torch.einsum(\"i,j->ij\", positions, inv_freq)  # (seq_len, head_dim/2)\n",
        "    sin = torch.sin(sinusoid_inp)[None, None, :, :]  # (1, 1, seq_len, head_dim/2)\n",
        "    cos = torch.cos(sinusoid_inp)[None, None, :, :]  # (1, 1, seq_len, head_dim/2)\n",
        "\n",
        "    # Split the input tensor into two halves and apply ROPE\n",
        "    x1, x2 = x[..., :head_dim//2], x[..., head_dim//2:]\n",
        "    x_rotated = torch.cat([x1 * cos - x2 * sin, x1 * sin + x2 * cos], dim=-1)\n",
        "    return x_rotated\n",
        "\n",
        "#####################################\n",
        "# Dataset and DataLoader: Wikitext (Hugging Face)\n",
        "#####################################\n",
        "class GPTDatasetV1(Dataset):\n",
        "    def __init__(self, text, tokenizer, max_length, stride):\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "\n",
        "        # Tokenize the text\n",
        "        token_ids = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "        # Create input-target pairs\n",
        "        for i in range(0, len(token_ids) - max_length, stride):\n",
        "            input_chunk = token_ids[i:i + max_length]\n",
        "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
        "            self.input_ids.append(torch.tensor(input_chunk))\n",
        "            self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx]\n",
        "\n",
        "def create_dataloader_v1(text, batch_size=4, max_length=256, stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
        "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "    dataset = GPTDatasetV1(text, tokenizer, max_length, stride)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last, num_workers=num_workers)\n",
        "    return dataloader\n",
        "\n",
        "def load_wikitext_data(num_lines=10000, dataset_name=\"wikitext\", subset=\"wikitext-103-raw-v1\"):\n",
        "    \"\"\"\n",
        "    Load Wikitext data from Hugging Face and concatenate the first `num_lines` lines into a single text.\n",
        "\n",
        "    Args:\n",
        "        num_lines (int): Number of lines to load.\n",
        "        dataset_name (str): Name of the dataset.\n",
        "        subset (str): Subset of the dataset.\n",
        "\n",
        "    Returns:\n",
        "        str: Concatenated text.\n",
        "    \"\"\"\n",
        "    ds = load_dataset(dataset_name, subset)\n",
        "    text_lines = ds[\"train\"][\"text\"][:num_lines]\n",
        "    text = \"\\n\".join(text_lines)\n",
        "    return text\n",
        "\n",
        "def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    Preprocess the text data by removing unwanted characters and normalizing whitespace.\n",
        "\n",
        "    Args:\n",
        "        text (str): Input text.\n",
        "\n",
        "    Returns:\n",
        "        str: Preprocessed text.\n",
        "    \"\"\"\n",
        "    # Remove special characters and digits, and normalize whitespace\n",
        "    text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "#####################################\n",
        "# Advanced Model Components (GPTModel)\n",
        "#####################################\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False, use_rope=False):\n",
        "        super().__init__()\n",
        "        assert d_out % num_heads == 0, \"d_out must be divisible by num_heads\"\n",
        "        self.d_out = d_out\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads\n",
        "\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.out_proj = nn.Linear(d_out, d_out)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.use_rope = use_rope\n",
        "        self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, num_tokens, _ = x.shape\n",
        "\n",
        "        keys = self.W_key(x).view(b, num_tokens, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        queries = self.W_query(x).view(b, num_tokens, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        values = self.W_value(x).view(b, num_tokens, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "\n",
        "        if self.use_rope:\n",
        "            queries = apply_rotary_pos_emb(queries)\n",
        "            keys = apply_rotary_pos_emb(keys)\n",
        "\n",
        "        attn_scores = queries @ keys.transpose(2, 3)\n",
        "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "        attn_scores.masked_fill_(mask_bool, float(\"-inf\"))\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores / math.sqrt(self.head_dim), dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        context_vec = (attn_weights @ values).transpose(1, 2).reshape(b, num_tokens, self.d_out)\n",
        "        context_vec = self.out_proj(context_vec)\n",
        "        return context_vec\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, emb_dim):\n",
        "        super().__init__()\n",
        "        self.eps = 1e-5\n",
        "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
        "        return self.scale * norm_x + self.shift\n",
        "\n",
        "class GELU(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1 + torch.tanh(math.sqrt(2.0 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
        "            GELU(),\n",
        "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.att = MultiHeadAttention(\n",
        "            d_in=cfg[\"emb_dim\"],\n",
        "            d_out=cfg[\"emb_dim\"],\n",
        "            context_length=cfg[\"context_length\"],\n",
        "            num_heads=cfg[\"n_heads\"],\n",
        "            dropout=cfg[\"drop_rate\"],\n",
        "            qkv_bias=cfg[\"qkv_bias\"],\n",
        "            use_rope=cfg.get(\"use_rope\", False)\n",
        "        )\n",
        "        self.ff = FeedForward(cfg)\n",
        "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "    def forward(self, x):\n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "        x = self.att(x)\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut\n",
        "\n",
        "        shortcut = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.ff(x)\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut\n",
        "        return x\n",
        "\n",
        "class GPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "        self.trf_blocks = nn.Sequential(*[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "\n",
        "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "        x = tok_embeds + pos_embeds\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits\n",
        "\n",
        "#####################################\n",
        "# Training and Evaluation Functions\n",
        "#####################################\n",
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "    logits = model(input_batch)\n",
        "    loss = nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
        "    return loss\n",
        "\n",
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "    total_loss = 0.0\n",
        "    if len(data_loader) == 0:\n",
        "        return float(\"nan\")\n",
        "    num_batches = num_batches if num_batches is not None else len(data_loader)\n",
        "    num_batches = min(num_batches, len(data_loader))\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            total_loss += loss.item()\n",
        "        else:\n",
        "            break\n",
        "    return total_loss / num_batches\n",
        "\n",
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "    model.train()\n",
        "    return train_loss, val_loss\n",
        "\n",
        "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
        "    for _ in range(max_new_tokens):\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "        logits = logits[:, -1, :]\n",
        "        idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
        "        idx = torch.cat((idx, idx_next), dim=1)\n",
        "    return idx\n",
        "\n",
        "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
        "    model.eval()\n",
        "    context_size = model.pos_emb.weight.shape[0]\n",
        "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
        "    with torch.no_grad():\n",
        "        token_ids = generate_text_simple(model=model, idx=encoded, max_new_tokens=50, context_size=context_size)\n",
        "        decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
        "        print(decoded_text.replace(\"\\n\", \" \"))\n",
        "    model.train()\n",
        "\n",
        "def text_to_token_ids(text, tokenizer):\n",
        "    encoded = tokenizer.encode(text)\n",
        "    return torch.tensor(encoded).unsqueeze(0)\n",
        "\n",
        "def token_ids_to_text(token_ids, tokenizer):\n",
        "    flat = token_ids.squeeze(0)\n",
        "    return tokenizer.decode(flat.tolist())\n",
        "\n",
        "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
        "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
        "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(\"Loss\")\n",
        "    ax1.legend(loc=\"upper right\")\n",
        "    ax2 = ax1.twiny()\n",
        "    ax2.plot(tokens_seen, train_losses, alpha=0)\n",
        "    ax2.set_xlabel(\"Tokens seen\")\n",
        "    fig.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "#####################################\n",
        "# Model Training\n",
        "#####################################\n",
        "def train_model(model, train_loader, val_loader, device, epochs=30, eval_iter=20, lr=1e-4):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    model.to(device)\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        epoch_loss = 0.0\n",
        "        start_time = time.time()\n",
        "\n",
        "        for batch_idx, (input_batch, target_batch) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "            if (batch_idx + 1) % 10 == 0:\n",
        "                print(f\"Epoch {epoch+1} Batch {batch_idx+1}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "        avg_loss = epoch_loss / len(train_loader)\n",
        "        elapsed = time.time() - start_time\n",
        "        print(f\"Epoch {epoch+1} completed (time: {elapsed:.2f}s), avg. loss: {avg_loss:.4f}\")\n",
        "        train_loss, val_loss = evaluate_model(model, train_loader, val_loader, device, eval_iter)\n",
        "        print(f\"Epoch {epoch+1} evaluation: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\\n\")\n",
        "\n",
        "#####################################\n",
        "# Text Generation\n",
        "#####################################\n",
        "def generate_sample(model, tokenizer, device, prompt, max_new_tokens=50):\n",
        "    print(\"Generated text sample:\\n\")\n",
        "    generate_and_print_sample(model, tokenizer, device, prompt)\n",
        "\n",
        "#####################################\n",
        "# Main Function\n",
        "#####################################\n",
        "def main():\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Load Wikitext data from Hugging Face and use the first 50k lines\n",
        "    text = load_wikitext_data(num_lines=50000, dataset_name=\"wikitext\", subset=\"wikitext-103-raw-v1\")\n",
        "\n",
        "    # Preprocess the text data\n",
        "    text = preprocess_text(text)\n",
        "\n",
        "    # Split data into training and validation sets (e.g., 90% train, 10% validation)\n",
        "    split_idx = int(0.9 * len(text))\n",
        "    train_text = text[:split_idx]\n",
        "    val_text = text[split_idx:]\n",
        "    train_loader = create_dataloader_v1(train_text, batch_size=8, max_length=256, stride=128)\n",
        "    val_loader = create_dataloader_v1(val_text, batch_size=8, max_length=256, stride=128)\n",
        "\n",
        "    # Tokenizer and advanced model configuration\n",
        "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "    cfg = {\n",
        "        \"vocab_size\": tokenizer.n_vocab,\n",
        "        \"emb_dim\": 256,\n",
        "        \"context_length\": 256,\n",
        "        \"drop_rate\": 0.1,\n",
        "        \"n_layers\": 6,\n",
        "        \"n_heads\": 8,\n",
        "        \"qkv_bias\": True,\n",
        "        \"use_rope\": True,\n",
        "    }\n",
        "\n",
        "    model = GPTModel(cfg)\n",
        "    train_model(model, train_loader, val_loader, device, epochs=1, eval_iter=25, lr=1e-5)\n",
        "\n",
        "    # Generate text after training with a given prompt\n",
        "    prompt = \"Valkyria Chronicles III \"\n",
        "    generate_sample(model, tokenizer, device, prompt, max_new_tokens=100)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-12T20:33:49.198352Z",
          "iopub.execute_input": "2025-02-12T20:33:49.198767Z",
          "iopub.status.idle": "2025-02-12T20:38:21.836553Z",
          "shell.execute_reply.started": "2025-02-12T20:33:49.198738Z",
          "shell.execute_reply": "2025-02-12T20:38:21.83572Z"
        },
        "id": "2E8o3nAXw_I3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import math\n",
        "import time\n",
        "\n",
        "#############################################\n",
        "# 1. Alternatif Normalizasyon: RMSNorm\n",
        "#############################################\n",
        "class RMSNorm(nn.Module):\n",
        "    def __init__(self, emb_dim, eps=1e-8):\n",
        "        super().__init__()\n",
        "        self.eps = eps\n",
        "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "    def forward(self, x):\n",
        "        # x shape: (..., emb_dim)\n",
        "        norm_x = x / torch.sqrt(torch.mean(x ** 2, dim=-1, keepdim=True) + self.eps)\n",
        "        return self.scale * norm_x\n",
        "\n",
        "def get_norm(norm_type, emb_dim):\n",
        "    if norm_type == 'layernorm':\n",
        "        return nn.LayerNorm(emb_dim)\n",
        "    elif norm_type == 'rmsnorm':\n",
        "        return RMSNorm(emb_dim)\n",
        "    else:\n",
        "        raise ValueError(\"Unknown normalization type\")\n",
        "\n",
        "#############################################\n",
        "# 2. Ortak Konfigürasyon\n",
        "#############################################\n",
        "class Config:\n",
        "    def __init__(self, vocab_size=30522, emb_dim=768, max_length=512, n_layers=4, n_heads=12,\n",
        "                 dropout=0.1, norm_type='layernorm'):\n",
        "        self.vocab_size = vocab_size\n",
        "        self.emb_dim = emb_dim\n",
        "        self.max_length = max_length\n",
        "        self.n_layers = n_layers\n",
        "        self.n_heads = n_heads\n",
        "        self.dropout = dropout\n",
        "        self.norm_type = norm_type  # 'layernorm' veya 'rmsnorm'\n",
        "        # Advanced varyantlar için ek parametreler:\n",
        "        self.latent_dim = emb_dim // 2   # RoPE ve latent projeksiyon için\n",
        "        self.num_experts = 4             # MoE FFN’de kullanılacak uzman sayısı\n",
        "\n",
        "#############################################\n",
        "# --- Attention Modülleri ---\n",
        "#############################################\n",
        "# 1. Standard Dot-Product Attention\n",
        "class StandardAttention(nn.Module):\n",
        "    def __init__(self, emb_dim, n_heads, dropout):\n",
        "        super().__init__()\n",
        "        assert emb_dim % n_heads == 0, \"Embedding boyutu baş sayısına tam bölünmeli.\"\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = emb_dim // n_heads\n",
        "        self.q_proj = nn.Linear(emb_dim, emb_dim)\n",
        "        self.k_proj = nn.Linear(emb_dim, emb_dim)\n",
        "        self.v_proj = nn.Linear(emb_dim, emb_dim)\n",
        "        self.out_proj = nn.Linear(emb_dim, emb_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch, seq_len, emb_dim = x.size()\n",
        "        Q = self.q_proj(x).view(batch, seq_len, self.n_heads, self.head_dim).transpose(1,2)\n",
        "        K = self.k_proj(x).view(batch, seq_len, self.n_heads, self.head_dim).transpose(1,2)\n",
        "        V = self.v_proj(x).view(batch, seq_len, self.n_heads, self.head_dim).transpose(1,2)\n",
        "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.head_dim)\n",
        "        attn = torch.softmax(scores, dim=-1)\n",
        "        attn = self.dropout(attn)\n",
        "        context = torch.matmul(attn, V)\n",
        "        context = context.transpose(1,2).contiguous().view(batch, seq_len, emb_dim)\n",
        "        return self.out_proj(context)\n",
        "\n",
        "# 2. RoPE Attention\n",
        "def apply_rope(x, base=10000):\n",
        "    # x: (batch, n_heads, seq_len, head_dim)\n",
        "    batch, n_heads, seq_len, head_dim = x.shape\n",
        "    inv_freq = 1.0 / (base ** (torch.arange(0, head_dim, 2, device=x.device).float() / head_dim))\n",
        "    pos = torch.arange(seq_len, device=x.device).float()\n",
        "    sinusoid_inp = torch.einsum(\"i,j->ij\", pos, inv_freq)  # (seq_len, head_dim/2)\n",
        "    sin = torch.sin(sinusoid_inp).unsqueeze(0).unsqueeze(0)\n",
        "    cos = torch.cos(sinusoid_inp).unsqueeze(0).unsqueeze(0)\n",
        "    x1 = x[..., :head_dim//2]\n",
        "    x2 = x[..., head_dim//2:]\n",
        "    return torch.cat([x1 * cos - x2 * sin, x1 * sin + x2 * cos], dim=-1)\n",
        "\n",
        "class RoPEAttention(nn.Module):\n",
        "    def __init__(self, emb_dim, n_heads, dropout):\n",
        "        super().__init__()\n",
        "        assert emb_dim % n_heads == 0, \"Embedding boyutu baş sayısına tam bölünmeli.\"\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = emb_dim // n_heads\n",
        "        self.q_proj = nn.Linear(emb_dim, emb_dim)\n",
        "        self.k_proj = nn.Linear(emb_dim, emb_dim)\n",
        "        self.v_proj = nn.Linear(emb_dim, emb_dim)\n",
        "        self.out_proj = nn.Linear(emb_dim, emb_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch, seq_len, emb_dim = x.size()\n",
        "        Q = self.q_proj(x).view(batch, seq_len, self.n_heads, self.head_dim).transpose(1,2)\n",
        "        K = self.k_proj(x).view(batch, seq_len, self.n_heads, self.head_dim).transpose(1,2)\n",
        "        V = self.v_proj(x).view(batch, seq_len, self.n_heads, self.head_dim).transpose(1,2)\n",
        "        Q = apply_rope(Q)\n",
        "        K = apply_rope(K)\n",
        "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.head_dim)\n",
        "        attn = torch.softmax(scores, dim=-1)\n",
        "        attn = self.dropout(attn)\n",
        "        context = torch.matmul(attn, V)\n",
        "        context = context.transpose(1,2).contiguous().view(batch, seq_len, emb_dim)\n",
        "        return self.out_proj(context)\n",
        "\n",
        "# 3. FlashAttention benzeri Attention (placeholder)\n",
        "def flash_attention(Q, K, V):\n",
        "    scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(Q.size(-1))\n",
        "    attn = torch.softmax(scores, dim=-1)\n",
        "    return torch.matmul(attn, V)\n",
        "\n",
        "class FlashAttentionModule(nn.Module):\n",
        "    def __init__(self, emb_dim, n_heads, dropout):\n",
        "        super().__init__()\n",
        "        assert emb_dim % n_heads == 0, \"Embedding boyutu baş sayısına tam bölünmeli.\"\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = emb_dim // n_heads\n",
        "        self.q_proj = nn.Linear(emb_dim, emb_dim)\n",
        "        self.k_proj = nn.Linear(emb_dim, emb_dim)\n",
        "        self.v_proj = nn.Linear(emb_dim, emb_dim)\n",
        "        self.out_proj = nn.Linear(emb_dim, emb_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch, seq_len, emb_dim = x.size()\n",
        "        Q = self.q_proj(x).view(batch, seq_len, self.n_heads, self.head_dim).transpose(1,2)\n",
        "        K = self.k_proj(x).view(batch, seq_len, self.n_heads, self.head_dim).transpose(1,2)\n",
        "        V = self.v_proj(x).view(batch, seq_len, self.n_heads, self.head_dim).transpose(1,2)\n",
        "        context = flash_attention(Q, K, V)\n",
        "        context = context.transpose(1,2).contiguous().view(batch, seq_len, emb_dim)\n",
        "        return self.out_proj(context)\n",
        "\n",
        "# 4. Multi-Query Attention: Keys & Values tek projeksiyon\n",
        "class MultiQueryAttention(nn.Module):\n",
        "    def __init__(self, emb_dim, n_heads, dropout):\n",
        "        super().__init__()\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = emb_dim // n_heads\n",
        "        self.q_proj = nn.Linear(emb_dim, emb_dim)\n",
        "        self.k_proj = nn.Linear(emb_dim, self.head_dim)\n",
        "        self.v_proj = nn.Linear(emb_dim, self.head_dim)\n",
        "        self.out_proj = nn.Linear(emb_dim, emb_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch, seq_len, emb_dim = x.size()\n",
        "        Q = self.q_proj(x).view(batch, seq_len, self.n_heads, self.head_dim).transpose(1,2)\n",
        "        K = self.k_proj(x).unsqueeze(1).expand(batch, self.n_heads, seq_len, self.head_dim)\n",
        "        V = self.v_proj(x).unsqueeze(1).expand(batch, self.n_heads, seq_len, self.head_dim)\n",
        "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.head_dim)\n",
        "        attn = torch.softmax(scores, dim=-1)\n",
        "        attn = self.dropout(attn)\n",
        "        context = torch.matmul(attn, V)\n",
        "        context = context.transpose(1,2).contiguous().view(batch, seq_len, emb_dim)\n",
        "        return self.out_proj(context)\n",
        "\n",
        "# 5. ALiBi Attention: Lineer bias ekleyerek göreceli pozisyon bilgisini entegre eder (Press et al., 2021)\n",
        "class ALiBiAttention(nn.Module):\n",
        "    def __init__(self, emb_dim, n_heads, dropout, alibi_scaling=-1.0):\n",
        "        super().__init__()\n",
        "        assert emb_dim % n_heads == 0, \"Embedding boyutu, baş sayısına tam bölünmeli.\"\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = emb_dim // n_heads\n",
        "        self.q_proj = nn.Linear(emb_dim, emb_dim)\n",
        "        self.k_proj = nn.Linear(emb_dim, emb_dim)\n",
        "        self.v_proj = nn.Linear(emb_dim, emb_dim)\n",
        "        self.out_proj = nn.Linear(emb_dim, emb_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.alibi_scaling = alibi_scaling\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch, seq_len, emb_dim = x.size()\n",
        "        Q = self.q_proj(x).view(batch, seq_len, self.n_heads, self.head_dim).transpose(1,2)\n",
        "        K = self.k_proj(x).view(batch, seq_len, self.n_heads, self.head_dim).transpose(1,2)\n",
        "        V = self.v_proj(x).view(batch, seq_len, self.n_heads, self.head_dim).transpose(1,2)\n",
        "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.head_dim)\n",
        "        # ALiBi bias: B[i,j] = (j - i) * scale\n",
        "        bias = torch.arange(seq_len, device=x.device).unsqueeze(0) - torch.arange(seq_len, device=x.device).unsqueeze(1)\n",
        "        bias = self.alibi_scaling * bias.float()\n",
        "        scores = scores + bias.unsqueeze(0).unsqueeze(0)\n",
        "        attn = torch.softmax(scores, dim=-1)\n",
        "        attn = self.dropout(attn)\n",
        "        context = torch.matmul(attn, V)\n",
        "        context = context.transpose(1,2).contiguous().view(batch, seq_len, emb_dim)\n",
        "        return self.out_proj(context)\n",
        "\n",
        "#############################################\n",
        "# --- FFN Varyantları ---\n",
        "#############################################\n",
        "# 1. Standart FFN\n",
        "class StandardFFN(nn.Module):\n",
        "    def __init__(self, emb_dim, expansion=4, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(emb_dim, expansion * emb_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(expansion * emb_dim, emb_dim)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# 2. MoE FFN\n",
        "class MoEFFN(nn.Module):\n",
        "    def __init__(self, emb_dim, num_experts, expansion=4, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.num_experts = num_experts\n",
        "        self.experts = nn.ModuleList([\n",
        "            nn.Sequential(\n",
        "                nn.Linear(emb_dim, expansion * emb_dim),\n",
        "                nn.GELU(),\n",
        "                nn.Dropout(dropout),\n",
        "                nn.Linear(expansion * emb_dim, emb_dim)\n",
        "            ) for _ in range(num_experts)\n",
        "        ])\n",
        "        self.gate = nn.Linear(emb_dim, num_experts)\n",
        "\n",
        "    def forward(self, x):\n",
        "        gate_scores = torch.softmax(self.gate(x), dim=-1)  # (batch, seq_len, num_experts)\n",
        "        expert_outputs = torch.stack([expert(x) for expert in self.experts], dim=-1)  # (batch, seq_len, emb_dim, num_experts)\n",
        "        gate_scores = gate_scores.unsqueeze(2)  # (batch, seq_len, 1, num_experts)\n",
        "        return (expert_outputs * gate_scores).sum(dim=-1)\n",
        "\n",
        "#############################################\n",
        "# --- Transformer Bloğu: Seçilebilir Attention ve FFN varyantları, Dropout, Pre-Norm ---\n",
        "#############################################\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, emb_dim, n_heads, attn_module, ffn_module, dropout, norm_type):\n",
        "        super().__init__()\n",
        "        self.norm1 = get_norm(norm_type, emb_dim)\n",
        "        self.attn = attn_module(emb_dim, n_heads, dropout)\n",
        "        self.norm2 = get_norm(norm_type, emb_dim)\n",
        "        self.ffn = ffn_module(emb_dim, dropout=dropout)  # ffn_module: StandardFFN or MoEFFN (for MoE, lambda is used)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.attn(self.norm1(x))\n",
        "        x = x + self.ffn(self.norm2(x))\n",
        "        return x\n",
        "\n",
        "#############################################\n",
        "# --- Transformer Modeli: Farklı varyantların seçilebildiği yapı ---\n",
        "#############################################\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, config, attn_variant='standard', ffn_variant='standard'):\n",
        "        super().__init__()\n",
        "        self.token_embed = nn.Embedding(config.vocab_size, config.emb_dim)\n",
        "        self.pos_embed   = nn.Embedding(config.max_length, config.emb_dim)\n",
        "\n",
        "        attn_dict = {\n",
        "            'standard': StandardAttention,\n",
        "            'rope': RoPEAttention,\n",
        "            'flash': FlashAttentionModule,\n",
        "            'multiquery': MultiQueryAttention,\n",
        "            'alibi': ALiBiAttention\n",
        "        }\n",
        "        ffn_dict = {\n",
        "            'standard': StandardFFN,\n",
        "            'moe': lambda emb_dim, dropout: MoEFFN(emb_dim, config.num_experts, dropout=dropout)\n",
        "        }\n",
        "        self.layers = nn.ModuleList([\n",
        "            TransformerBlock(config.emb_dim, config.n_heads, attn_dict[attn_variant], ffn_dict[ffn_variant], config.dropout, config.norm_type)\n",
        "            for _ in range(config.n_layers)\n",
        "        ])\n",
        "        self.norm = get_norm(config.norm_type, config.emb_dim)\n",
        "        self.output_proj = nn.Linear(config.emb_dim, config.vocab_size, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        seq_len = x.size(1)\n",
        "        x = self.token_embed(x) + self.pos_embed(torch.arange(seq_len, device=x.device))\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        x = self.norm(x)\n",
        "        return self.output_proj(x)\n",
        "\n",
        "#############################################\n",
        "# --- Ek: Model Özeti ve Parametre Sayısı Fonksiyonu ---\n",
        "#############################################\n",
        "def model_summary(model):\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print(f\"Toplam Parametre: {total_params:,}\")\n",
        "    print(f\"Eğitilebilir Parametre: {trainable:,}\")\n",
        "\n",
        "#############################################\n",
        "# --- Ek: Greedy Decoding Fonksiyonu ---\n",
        "#############################################\n",
        "def greedy_decode(model, start_token, max_length, device):\n",
        "    model.eval()\n",
        "    generated = [start_token]\n",
        "    input_seq = torch.tensor([generated], device=device)\n",
        "    with torch.no_grad():\n",
        "        for _ in range(max_length - 1):\n",
        "            logits = model(input_seq)  # (batch, seq_len, vocab_size)\n",
        "            next_token = torch.argmax(logits[0, -1, :]).item()\n",
        "            generated.append(next_token)\n",
        "            input_seq = torch.tensor([generated], device=device)\n",
        "    model.train()\n",
        "    return generated\n",
        "\n",
        "#############################################\n",
        "# --- Ek: Basit Eğitim Döngüsü (Training Loop) ---\n",
        "#############################################\n",
        "def train_model(model, config, epochs=3):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    # Dummy dataset: rastgele token dizileri\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        dummy_input = torch.randint(0, config.vocab_size, (8, config.max_length), device=device)\n",
        "        dummy_target = torch.randint(0, config.vocab_size, (8, config.max_length), device=device)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(dummy_input)  # (batch, seq_len, vocab_size)\n",
        "        loss = loss_fn(logits.view(-1, config.vocab_size), dummy_target.view(-1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "#############################################\n",
        "# --- Detaylı Test Fonksiyonları (Önceki Versiyonun Geliştirilmiş Hali) ---\n",
        "#############################################\n",
        "def run_detailed_tests(config, variant_list):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    for variant in variant_list:\n",
        "        attn_var = variant['attn']\n",
        "        ffn_var = variant['ffn']\n",
        "        print(f\"\\nTest: Attention = {attn_var}, FFN = {ffn_var}\")\n",
        "        model = TransformerModel(config, attn_variant=attn_var, ffn_variant=ffn_var).to(device)\n",
        "        model_summary(model)\n",
        "        model.train()\n",
        "        dummy_input = torch.randint(0, config.vocab_size, (4, config.max_length), device=device)\n",
        "        logits = model(dummy_input)\n",
        "        loss = nn.CrossEntropyLoss()(logits.view(-1, config.vocab_size),\n",
        "                                     torch.randint(0, config.vocab_size, (4 * config.max_length,), device=device))\n",
        "        loss.backward()\n",
        "        print(f\"Loss: {loss.item():.4f}, Output shape: {logits.shape}\")\n",
        "\n",
        "        torch.cuda.synchronize() if device.type == 'cuda' else None\n",
        "        start_time = time.time()\n",
        "        for _ in range(10):\n",
        "            _ = model(dummy_input)\n",
        "        torch.cuda.synchronize() if device.type == 'cuda' else None\n",
        "        avg_time = (time.time() - start_time) / 10.0\n",
        "        print(f\"Ortalama ileri geçiş süresi: {avg_time:.6f} sn\")\n",
        "\n",
        "        # Greedy decoding test (ilk 10 token üretiliyor)\n",
        "        start_token = dummy_input[0, 0].item()\n",
        "        generated = greedy_decode(model, start_token, max_length=10, device=device)\n",
        "        print(f\"Greedy Decode Çıktısı: {generated}\")\n",
        "\n",
        "#############################################\n",
        "# --- Ana Çalışma Bölümü: Farklı varyantları deneyelim ---\n",
        "#############################################\n",
        "if __name__ == \"__main__\":\n",
        "    # Konfigürasyona norm tipi ve dropout eklenmiştir.\n",
        "    config = Config(vocab_size=30522, emb_dim=768, max_length=128, n_layers=4, n_heads=12, dropout=0.1, norm_type='rmsnorm')\n",
        "\n",
        "    # Denenecek varyantlar: farklı attention ve FFN varyantları\n",
        "    variant_list = [\n",
        "        {'attn': 'standard', 'ffn': 'standard'},\n",
        "        {'attn': 'rope',     'ffn': 'standard'},\n",
        "        {'attn': 'flash',    'ffn': 'standard'},\n",
        "        {'attn': 'multiquery', 'ffn': 'standard'},\n",
        "        {'attn': 'alibi',    'ffn': 'standard'},\n",
        "        {'attn': 'standard', 'ffn': 'moe'},\n",
        "        {'attn': 'rope',     'ffn': 'moe'},\n",
        "        {'attn': 'flash',    'ffn': 'moe'},\n",
        "        {'attn': 'multiquery', 'ffn': 'moe'},\n",
        "        {'attn': 'alibi',    'ffn': 'moe'},\n",
        "    ]\n",
        "\n",
        "    print(\"=== Detaylı Varyant Testleri ===\")\n",
        "    run_detailed_tests(config, variant_list)\n",
        "\n",
        "    print(\"\\n=== Eğitim Döngüsü Testi ===\")\n",
        "    # Bir varyant seçelim (örneğin, gelişmiş varyant: RoPE + MoE FFN)\n",
        "    model = TransformerModel(config, attn_variant='rope', ffn_variant='moe').to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
        "    train_model(model, config, epochs=3)\n",
        "\n",
        "    print(\"\\n=== Greedy Decoding Testi ===\")\n",
        "    # Greedy decoding örneği: İlk tokenı dummy inputtan alıp 20 token üretelim\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    prompt_token = torch.randint(0, config.vocab_size, (1,)).item()\n",
        "    generated_tokens = greedy_decode(model, prompt_token, max_length=20, device=device)\n",
        "    print(\"Üretilen Tokenlar:\", generated_tokens)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-12T22:04:05.352069Z",
          "iopub.execute_input": "2025-02-12T22:04:05.352443Z",
          "iopub.status.idle": "2025-02-12T22:06:42.132452Z",
          "shell.execute_reply.started": "2025-02-12T22:04:05.352413Z",
          "shell.execute_reply": "2025-02-12T22:06:42.131334Z"
        },
        "id": "4Q_jYSvEw_I3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install evaluate reportlab"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-12T22:06:55.854229Z",
          "iopub.execute_input": "2025-02-12T22:06:55.854996Z",
          "iopub.status.idle": "2025-02-12T22:06:55.861061Z",
          "shell.execute_reply.started": "2025-02-12T22:06:55.854884Z",
          "shell.execute_reply": "2025-02-12T22:06:55.859524Z"
        },
        "id": "6ZXigQy4w_I4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import math\n",
        "from datasets import load_dataset\n",
        "from collections import defaultdict\n",
        "from reportlab.lib.pagesizes import A4\n",
        "from reportlab.pdfgen import canvas\n",
        "\n",
        "#############################################\n",
        "# Turkish-Alpaca Veri Seti ve Tokenizer\n",
        "#############################################\n",
        "class TurkishAlpacaDataset:\n",
        "    def __init__(self, config):\n",
        "        # Hugging Face'den veri setini yükle\n",
        "        dataset = load_dataset(\"TFLai/Turkish-Alpaca\")\n",
        "        self.instructions = dataset['train']['instruction'][:100]  # Limit to 100 samples\n",
        "        self.outputs = dataset['train']['output'][:100]            # Limit to 100 samples\n",
        "\n",
        "        # Tokenizer oluştur\n",
        "        self.vocab = defaultdict(lambda: len(self.vocab))\n",
        "        self.vocab['<pad>'] = 0  # Padding token'i ekle\n",
        "\n",
        "        # Tüm veriyi tokenize et\n",
        "        self.tokenize_data()\n",
        "\n",
        "        # Inverse vocab oluştur\n",
        "        self.inverse_vocab = {v: k for k, v in self.vocab.items()}\n",
        "\n",
        "        # Dynamically update vocab_size in config\n",
        "        config.vocab_size = len(self.vocab)\n",
        "        self.config = config\n",
        "\n",
        "    def tokenize_data(self):\n",
        "        # Instruction ve Output'u tokenize et\n",
        "        self.tokenized_instructions = []\n",
        "        self.tokenized_outputs = []\n",
        "\n",
        "        for inst, out in zip(self.instructions, self.outputs):\n",
        "            inst_tokens = [self.vocab[word] for word in inst.split()]\n",
        "            out_tokens = [self.vocab[word] for word in out.split()]\n",
        "            self.tokenized_instructions.append(inst_tokens)\n",
        "            self.tokenized_outputs.append(out_tokens)\n",
        "\n",
        "    def get_batch(self, batch_size=4):\n",
        "        # Rastgele bir batch oluştur\n",
        "        indices = torch.randint(0, len(self.tokenized_instructions), (batch_size,))\n",
        "        inputs, targets = [], []\n",
        "\n",
        "        for i in indices:\n",
        "            input_tokens = self.tokenized_instructions[i][:-1]\n",
        "            target_tokens = self.tokenized_outputs[i][1:]\n",
        "            inputs.append(torch.tensor(input_tokens, dtype=torch.long))\n",
        "            targets.append(torch.tensor(target_tokens, dtype=torch.long))\n",
        "\n",
        "        # Padding işlemi\n",
        "        inputs = torch.nn.utils.rnn.pad_sequence(inputs, batch_first=True, padding_value=0)\n",
        "        targets = torch.nn.utils.rnn.pad_sequence(targets, batch_first=True, padding_value=0)\n",
        "        return inputs, targets\n",
        "\n",
        "\n",
        "#############################################\n",
        "# Greedy Decode Function\n",
        "#############################################\n",
        "def greedy_decode(model, start_token, max_length, device, temperature=1.0):\n",
        "    \"\"\"\n",
        "    Greedy decoding to generate sequences from a language model.\n",
        "\n",
        "    Args:\n",
        "        model: The language model to use for generation.\n",
        "        start_token: The token ID to start decoding from.\n",
        "        max_length: Maximum length of the generated sequence.\n",
        "        device: The device (CPU/GPU) where the model resides.\n",
        "        temperature: Sampling temperature (optional, default=1.0).\n",
        "\n",
        "    Returns:\n",
        "        List of generated token IDs.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        input_token = torch.tensor([[start_token]], dtype=torch.long).to(device)\n",
        "        generated_tokens = [start_token]\n",
        "\n",
        "        for _ in range(max_length - 1):\n",
        "            logits = model(input_token)\n",
        "            next_token_logits = logits[:, -1, :] / temperature\n",
        "            next_token = torch.argmax(next_token_logits, dim=-1).item()\n",
        "\n",
        "            if next_token == 0:  # Stop if <pad> token is generated\n",
        "                break\n",
        "\n",
        "            generated_tokens.append(next_token)\n",
        "            input_token = torch.cat([input_token, torch.tensor([[next_token]], dtype=torch.long).to(device)], dim=1)\n",
        "\n",
        "    return generated_tokens\n",
        "\n",
        "\n",
        "#############################################\n",
        "# Geliştirilmiş Eğitim ve Değerlendirme\n",
        "#############################################\n",
        "def train_and_evaluate(model, config, epochs=10):\n",
        "    device = next(model.parameters()).device\n",
        "    dataset = TurkishAlpacaDataset(config)\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=1e-4)  # Learning rate artırıldı\n",
        "    loss_fn = nn.CrossEntropyLoss(ignore_index=0)\n",
        "\n",
        "    print(f\"\\n{'='*40}\")\n",
        "    print(f\"🏁 {model.name} Eğitime Başlıyor...\")\n",
        "    print(f\"🔢 Toplam Token Sayısı: {len(dataset.vocab)}\")\n",
        "    print(f\"⚙️  Kullanılan Donanım: {'GPU' if device.type=='cuda' else 'CPU'}\")\n",
        "    print(f\"{'='*40}\\n\")\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        inputs, targets = dataset.get_batch(batch_size=8)  # Batch size artırıldı\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(inputs)\n",
        "        logits = logits.view(-1, config.vocab_size)  # Reshape logits\n",
        "        targets = targets.view(-1)                  # Reshape targets\n",
        "        loss = loss_fn(logits, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Eğitim Metrikleri\n",
        "        preds = torch.argmax(logits, dim=-1)\n",
        "        mask = targets != 0\n",
        "        correct = (preds[mask] == targets[mask]).sum().item()\n",
        "        total = mask.sum().item()\n",
        "        acc = correct / total if total > 0 else 0\n",
        "        ppl = math.exp(loss.item())\n",
        "\n",
        "        print(f\"Epok {epoch+1}/{epochs} | \"\n",
        "              f\"Kayıp: {loss.item():.3f} | \"\n",
        "              f\"Doğruluk: {acc:.1%} | \"\n",
        "              f\"Perplexity: {ppl:.2f}\")\n",
        "\n",
        "    # Son Değerlendirme\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        inputs, targets = dataset.get_batch(batch_size=8)\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        logits = model(inputs)\n",
        "        logits = logits.view(-1, config.vocab_size)  # Reshape logits\n",
        "        targets = targets.view(-1)                  # Reshape targets\n",
        "        loss = loss_fn(logits, targets)\n",
        "\n",
        "        # Metrik Hesaplama\n",
        "        preds = torch.argmax(logits, dim=-1)\n",
        "        mask = targets != 0\n",
        "        correct = (preds[mask] == targets[mask]).sum().item()\n",
        "        total = mask.sum().item()\n",
        "        final_acc = correct / total if total > 0 else 0\n",
        "        final_ppl = math.exp(loss.item())\n",
        "\n",
        "        # Örnek Üretim\n",
        "        start_word = dataset.instructions[0].split()[0]\n",
        "        input_token = dataset.vocab[start_word]\n",
        "        generated = greedy_decode(model, input_token, max_length=config.max_length, device=device)\n",
        "        generated_sentence = ' '.join([dataset.inverse_vocab.get(t, \"?\") for t in generated])\n",
        "\n",
        "    print(f\"\\n⭐ Final Performans ⭐\")\n",
        "    print(f\"|{'Metric':<15}|{'Değer':<15}|\")\n",
        "    print(f\"|{'-'*15}|{'-'*15}|\")\n",
        "    print(f\"|{'Kayıp':<15}|{loss.item():.3f}|\")\n",
        "    print(f\"|{'Doğruluk':<15}|{final_acc:.1%}|\")\n",
        "    print(f\"|{'Perplexity':<15}|{final_ppl:.2f}|\")\n",
        "    print(f\"\\n🔮 Örnek Çıktı: {generated_sentence}\")\n",
        "\n",
        "    # Metrikleri döndür\n",
        "    return {\n",
        "        'parameters': sum(p.numel() for p in model.parameters()),\n",
        "        'trainable_parameters': sum(p.numel() for p in model.parameters() if p.requires_grad),\n",
        "        'loss': loss.item(),\n",
        "        'accuracy': final_acc,\n",
        "        'perplexity': final_ppl,\n",
        "        'sample_outputs': [generated_sentence]\n",
        "    }\n",
        "\n",
        "\n",
        "#############################################\n",
        "# PDF Oluşturma Fonksiyonu (reportlab ile)\n",
        "#############################################\n",
        "def save_results_to_pdf(metrics, model_name):\n",
        "    # PDF dosyasını oluştur\n",
        "    pdf_path = f\"{model_name}_degerlendirme.pdf\"\n",
        "    c = canvas.Canvas(pdf_path, pagesize=A4)\n",
        "    width, height = A4\n",
        "\n",
        "    # Başlık\n",
        "    c.setFont(\"Helvetica-Bold\", 16)\n",
        "    c.drawString(50, height - 50, f\"Model Değerlendirme Raporu: {model_name}\")\n",
        "\n",
        "    # Metrikler\n",
        "    c.setFont(\"Helvetica\", 12)\n",
        "    y = height - 80\n",
        "    c.drawString(50, y, \"📊 Performans Metrikleri\")\n",
        "    y -= 20\n",
        "    c.drawString(50, y, f\"Toplam Parametre Sayısı: {metrics['parameters']:,}\")\n",
        "    y -= 20\n",
        "    c.drawString(50, y, f\"Eğitilebilir Parametre Sayısı: {metrics['trainable_parameters']:,}\")\n",
        "    y -= 20\n",
        "    c.drawString(50, y, f\"Kayıp: {metrics['loss']:.3f}\")\n",
        "    y -= 20\n",
        "    c.drawString(50, y, f\"Doğruluk: {metrics['accuracy']:.1%}\")\n",
        "    y -= 20\n",
        "    c.drawString(50, y, f\"Perplexity: {metrics['perplexity']:.2f}\")\n",
        "\n",
        "    # Örnek Çıktılar\n",
        "    y -= 30\n",
        "    c.drawString(50, y, \"🔮 Örnek Çıktılar\")\n",
        "    y -= 20\n",
        "    for i, output in enumerate(metrics['sample_outputs']):\n",
        "        c.drawString(50, y, f\"Örnek {i+1}: {output}\")\n",
        "        y -= 20\n",
        "\n",
        "    # PDF'i kaydet\n",
        "    c.save()\n",
        "    print(f\"📄 {model_name} için rapor PDF olarak kaydedildi: {pdf_path}\")\n",
        "\n",
        "\n",
        "#############################################\n",
        "# Dummy Transformer Model for Testing\n",
        "#############################################\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, config, attn_type, ffn_type):\n",
        "        super().__init__()\n",
        "        self.name = f\"{attn_type}-{ffn_type}\"\n",
        "        self.embedding = nn.Embedding(config.vocab_size, config.emb_dim)\n",
        "        self.transformer = nn.Transformer(\n",
        "            d_model=config.emb_dim,\n",
        "            nhead=config.n_heads,\n",
        "            num_encoder_layers=config.n_layers,\n",
        "            num_decoder_layers=config.n_layers,\n",
        "            dim_feedforward=config.emb_dim * 4,\n",
        "            dropout=config.dropout\n",
        "        )\n",
        "        self.fc_out = nn.Linear(config.emb_dim, config.vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = self.transformer(x, x)\n",
        "        x = self.fc_out(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Konfigürasyon\n",
        "    class Config:\n",
        "        def __init__(self):\n",
        "            self.vocab_size = 100  # Bu değer dinamik olarak güncellenecek\n",
        "            self.emb_dim = 256     # Embedding boyutu artırıldı\n",
        "            self.max_length = 32   # Maksimum uzunluk artırıldı\n",
        "\n",
        "            # Veri setinden maksimum uzunluğu hesapla\n",
        "            dataset = load_dataset(\"TFLai/Turkish-Alpaca\")\n",
        "            instructions = dataset['train']['instruction'][:100]  # Limit to 100 samples\n",
        "            outputs = dataset['train']['output'][:100]            # Limit to 100 samples\n",
        "\n",
        "            instruction_lengths = [len(inst.split()) for inst in instructions]\n",
        "            output_lengths = [len(out.split()) for out in outputs]\n",
        "\n",
        "            max_instruction_length = max(instruction_lengths)\n",
        "            max_output_length = max(output_lengths)\n",
        "\n",
        "            # max_length'ı instruction ve output'un maksimum uzunluğuna göre ayarla\n",
        "            self.max_length = max(max_instruction_length, max_output_length) + 10  # Ekstra pay bırak\n",
        "\n",
        "            self.n_layers = 4      # Katman sayısı artırıldı\n",
        "            self.n_heads = 8       # Head sayısı artırıldı\n",
        "            self.dropout = 0.1\n",
        "            self.norm_type = 'rmsnorm'\n",
        "            self.num_experts = 2\n",
        "\n",
        "    config = Config()\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Test Edilecek Modeller\n",
        "    experiments = [\n",
        "        {'attn': 'standard', 'ffn': 'standard', 'name': 'Standart Model'},\n",
        "        {'attn': 'rope', 'ffn': 'standard', 'name': 'RoPE Dikkat'},\n",
        "        {'attn': 'alibi', 'ffn': 'moe', 'name': 'ALiBi + MoE'},\n",
        "        {'attn': 'multiquery', 'ffn': 'moe', 'name': 'Multi-Query MoE'}\n",
        "    ]\n",
        "\n",
        "    # Deneyleri Çalıştır\n",
        "    results = []\n",
        "    for exp in experiments:\n",
        "        print(f\"\\n{'='*40}\")\n",
        "        print(f\"🧪 {exp['name']} Değerlendiriliyor...\")\n",
        "        print(f\"{'='*40}\")\n",
        "\n",
        "        model = TransformerModel(config, exp['attn'], exp['ffn']).to(device)\n",
        "        model.name = exp['name']\n",
        "\n",
        "        # Eğitim ve Değerlendirme\n",
        "        metrics = train_and_evaluate(model, config, epochs=20)  # Epoch sayısı artırıldı\n",
        "        results.append((exp['name'], metrics))\n",
        "\n",
        "        # PDF Raporu Oluştur\n",
        "        save_results_to_pdf(metrics, exp['name'])\n",
        "\n",
        "    # Tüm Sonuçları Karşılaştır\n",
        "    print(\"\\n📊 Tüm Modellerin Karşılaştırması:\")\n",
        "    print(f\"|{'Model':<20}|{'Parametre':<10}|{'Doğruluk':<10}|{'Perplexity':<12}|\")\n",
        "    print(f\"|{'-'*20}|{'-'*10}|{'-'*10}|{'-'*12}|\")\n",
        "    for name, metrics in results:\n",
        "        print(f\"|{name:<20}|{metrics['parameters']:<10,}|{metrics['accuracy']:<10.1%}|{metrics['perplexity']:<12.2f}|\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-12T22:11:53.299779Z",
          "iopub.execute_input": "2025-02-12T22:11:53.300209Z",
          "iopub.status.idle": "2025-02-12T22:11:55.659114Z",
          "shell.execute_reply.started": "2025-02-12T22:11:53.300168Z",
          "shell.execute_reply": "2025-02-12T22:11:55.657535Z"
        },
        "id": "Gdew4V4fw_I4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "İşlem için CPU ve GPU yetersiz o yüzden bu uyarı geliyor"
      ],
      "metadata": {
        "id": "6f-KvTbfw_I4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "HhxJ5m_Dw_I5"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}
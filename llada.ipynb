{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e726e7e",
   "metadata": {},
   "source": [
    "# Difüzyon Temelli Metin Üretimi (SE Data Set ile)\n",
    "Bu notebook, HuggingFace'den alınan `salihturkoglu/se_data_set` veri setinin `instruction` ve `response` sütunlarını kullanarak difüzyon temelli metin üretimini gösterir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed42a70",
   "metadata": {},
   "source": [
    "## 1. Veri Setini İndir ve Hazırla\n",
    "Veri seti HuggingFace Datasets ile yüklenir. Her bir örnek için `instruction` giriş, `response` ise hedef metindir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d67b069a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "\n",
    "# HuggingFace veri setini yükle\n",
    "dataset = load_dataset('salihturkoglu/se_data_set', split='train')\n",
    "\n",
    "# Tüm örnekleri kullan (877 satır var)\n",
    "instructions = [ex['instruction'] for ex in dataset]\n",
    "responses = [ex['response'] for ex in dataset]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0ef5f0",
   "metadata": {},
   "source": [
    "## 2. Tokenizer ve Sözlük Oluşturma\n",
    "Tüm metinlerden bir kelime sözlüğü oluşturulur ve metinler tokenlara çevrilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "447747d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def tokenize(text):\n",
    "    return text.lower().strip().split()\n",
    "\n",
    "# Sözlük oluştur\n",
    "PAD_TOKEN = '<PAD>'\n",
    "UNK_TOKEN = '<UNK>'\n",
    "all_texts = instructions + responses\n",
    "counter = Counter()\n",
    "for text in all_texts:\n",
    "    counter.update(tokenize(text))\n",
    "\n",
    "vocab_list = [PAD_TOKEN, UNK_TOKEN] + [tok for tok, count in counter.items() if count >= 2][:10000]\n",
    "vocab = {tok: idx for idx, tok in enumerate(vocab_list)}\n",
    "reverse_vocab = {idx: tok for tok, idx in vocab.items()}\n",
    "\n",
    "def encode(text):\n",
    "    return [vocab.get(tok, vocab[UNK_TOKEN]) for tok in tokenize(text)]\n",
    "\n",
    "def decode(token_ids):\n",
    "    return ' '.join([reverse_vocab.get(idx, UNK_TOKEN) for idx in token_ids if idx != vocab[PAD_TOKEN]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0708a4b5",
   "metadata": {},
   "source": [
    "## 3. PyTorch Dataset ve DataLoader\n",
    "Instruction ve response çiftlerini uygun şekilde tensor haline getirir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb7245eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InstructionResponseDataset(Dataset):\n",
    "    def __init__(self, instructions, responses, vocab, max_len=64):\n",
    "        self.inputs = [encode(text)[:max_len] for text in instructions]\n",
    "        self.targets = [encode(text)[:max_len] for text in responses]\n",
    "        self.max_len = max_len\n",
    "        self.vocab = vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inp = self.inputs[idx]\n",
    "        tgt = self.targets[idx]\n",
    "        inp = inp + [self.vocab['<PAD>']] * (self.max_len - len(inp))\n",
    "        tgt = tgt + [self.vocab['<PAD>']] * (self.max_len - len(tgt))\n",
    "        return torch.tensor(inp, dtype=torch.long), torch.tensor(tgt, dtype=torch.long)\n",
    "\n",
    "max_len = 128\n",
    "dataset = InstructionResponseDataset(instructions, responses, vocab, max_len=max_len)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651c71c8",
   "metadata": {},
   "source": [
    "## 4. Difüzyon Süreci: Gürültü Ekleme ve Çıkarma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4b3c522",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(batch, noise_level=0.5):\n",
    "    noisy = batch.clone()\n",
    "    mask = (torch.rand(noisy.shape) < noise_level)\n",
    "    random_tokens = torch.randint(2, len(vocab), noisy.shape, device=batch.device)\n",
    "    noisy[mask] = random_tokens[mask]\n",
    "    return noisy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5997f6c3",
   "metadata": {},
   "source": [
    "## 5. Model Tanımı"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69d48719",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffusionTextModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim=256, hidden_dim=2048, num_layers=8, nhead=8):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embedding_dim, nhead=nhead, dim_feedforward=hidden_dim, batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.fc = nn.Linear(embedding_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x, src_key_padding_mask=None):\n",
    "        emb = self.embedding(x)\n",
    "        out = self.transformer(emb, src_key_padding_mask=src_key_padding_mask)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b7055b",
   "metadata": {},
   "source": [
    "## 6. Eğitim Süreci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bc574d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 7.2675\n",
      "Epoch 2, Loss: 6.5326\n",
      "Epoch 3, Loss: 5.9995\n",
      "Epoch 4, Loss: 5.6588\n",
      "Epoch 5, Loss: 5.4110\n",
      "Epoch 6, Loss: 5.2345\n",
      "Epoch 7, Loss: 5.0627\n",
      "Epoch 8, Loss: 4.9098\n",
      "Epoch 9, Loss: 4.7601\n",
      "Epoch 10, Loss: 4.6605\n",
      "Epoch 11, Loss: 4.5139\n",
      "Epoch 12, Loss: 4.4244\n",
      "Epoch 13, Loss: 4.3298\n",
      "Epoch 14, Loss: 4.2664\n",
      "Epoch 15, Loss: 4.1858\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = DiffusionTextModel(len(vocab)).to(device)\n",
    "\n",
    "def train_diffusion_model(model, dataloader, epochs=15, noise_level=0.5):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=vocab['<PAD>'])\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch_inputs, batch_targets in dataloader:\n",
    "            batch_inputs = batch_inputs.to(device)\n",
    "            batch_targets = batch_targets.to(device)\n",
    "            noisy_inputs = add_noise(batch_targets, noise_level)\n",
    "            mask = (batch_targets == vocab['<PAD>'])\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(noisy_inputs, src_key_padding_mask=mask)\n",
    "            loss = criterion(outputs.view(-1, outputs.size(-1)), batch_targets.view(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}, Loss: {total_loss/len(dataloader):.4f}\")\n",
    "\n",
    "train_diffusion_model(model, dataloader, epochs=15, noise_level=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edb3735",
   "metadata": {},
   "source": [
    "## 7. Metin Üretimi (Difüzyon ile Response Oluşturma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a29fd606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: Yazılım Mühendisliği bölümünün ders programını görebilir miyim?\n",
      "Gerçek Response: Güncel ders programını bölüm web sitesindeki duyurular bölümündeki en güncel ders programı duyurusuna ulaşarak görebilirsiniz.\n",
      "Model Response: öğrenci ve eğitimi ve fazla i̇şyeri i̇şyeri öğrenci eğitimi i̇şyeri bilgi i̇şyeri ise, ile ders ile ders en ve en eğitimi ile ders bölümün ile eğitimi öğrenci ders için i̇şyeri ve eğitimi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emreq\\Desktop\\Transformers\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:508: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. We recommend specifying layout=torch.jagged when constructing a nested tensor, as this layout receives active development, has better operator coverage, and works with torch.compile. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\NestedTensorImpl.cpp:182.)\n",
      "  output = torch._nested_tensor_from_mask(\n"
     ]
    }
   ],
   "source": [
    "def generate_response(model, instruction, steps=8, max_len=32):\n",
    "    model.eval()\n",
    "    inp = encode(instruction)[:max_len]\n",
    "    inp = inp + [vocab['<PAD>']] * (max_len - len(inp))\n",
    "    inp_tensor = torch.tensor([inp], dtype=torch.long, device=device)\n",
    "    # Başlangıçta tamamen rastgele bir dizi\n",
    "    generated = torch.randint(2, len(vocab), (1, max_len), device=device)\n",
    "    for step in range(steps):\n",
    "        mask = (generated == vocab['<PAD>'])\n",
    "        with torch.no_grad():\n",
    "            outputs = model(generated, src_key_padding_mask=mask)\n",
    "            predicted = outputs.argmax(dim=-1)\n",
    "        prob = 1.0 - (step + 1) / steps\n",
    "        random_mask = (torch.rand_like(generated.float()) < prob)\n",
    "        generated[random_mask] = predicted[random_mask]\n",
    "    tokens = generated[0].tolist()\n",
    "    return decode(tokens)\n",
    "\n",
    "# Örnek bir instruction ile response üret\n",
    "test_instruction = instructions[0]\n",
    "print('Instruction:', test_instruction)\n",
    "print('Gerçek Response:', responses[0])\n",
    "print('Model Response:', generate_response(model, test_instruction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12708af5",
   "metadata": {},
   "source": [
    "## 9. Test: Herhangi Bir Soru ile Modeli Deneyin\n",
    "Aşağıdaki hücrede, istediğiniz bir soruyu `test_instruction` değişkenine yazarak modelin cevabını görebilirsiniz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9e1eacd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction: Ders kaydı yaparken üst sınıftan ders alabilir miyim?\n",
      "Gerçek Response: Yok\n",
      "Model Response: akademik veya yapılır. öğrenci öğrenci ve ders ders ve ders olan üzerinden ve öğrenci akademik veya öğrenci teknoloji ve veya yönetimi için ders öğrenci veya ve ve bölümün bilgi öğrenci veya ders en olan resmi öğrenci akademik akademik akademik sistemi öğrenci en öğrenci ders öğrenci ile bir öğrenci öğrenci ve bir istediği öğrenci ve ve genellikle sayfasından tüm sistemi öğrenci olmak ilgili değişim öğrenci ders ders öğrenci ve sistemi onaylandıktan öğrenci ders genellikle akademik ve veya ders ders üniversite öğrenci hizmetlerinden fakültesi ve içindeki ve ile bilgi öğrenci ders ve olanakları bir öğrenci akademik veya ve ders bilgi ders öğrenci (katkı ve 4. için ve için da bilgi istediği bilgiye ve fazla ve bir sağlamak ve akademik olan ve ve akademik ve ve sağlanır. öğrenci bir web öğrenci\n"
     ]
    }
   ],
   "source": [
    "# Test etmek istediğiniz soruyu buradan değiştirebilirsiniz.\n",
    "test_instruction = \"Ders kaydı yaparken üst sınıftan ders alabilir miyim?\"\n",
    "\n",
    "print('Instruction:', test_instruction)\n",
    "print('Gerçek Response:', responses[instructions.index(test_instruction)] if test_instruction in instructions else \"Yok\")\n",
    "print('Model Response:', generate_response(model, test_instruction, max_len=max_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caed78d5",
   "metadata": {},
   "source": [
    "## 10. Modelin Test Edilmesi\n",
    "Aşağıdaki hücrede modelin test verisi üzerinde ne kadar doğru response üretebildiği ölçülür. Basit bir doğruluk metriği olarak, modelin response üretiminde orijinal response ile token bazında ne kadar örtüştüğü hesaplanır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83d0357a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test doğruluğu: 1.71% (60/3509)\n"
     ]
    }
   ],
   "source": [
    "def evaluate_diffusion_model(model, dataset, n_samples=100, steps=8):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for i in range(min(n_samples, len(dataset))):\n",
    "        inp, tgt = dataset[i]\n",
    "        inp = inp.unsqueeze(0).to(device)\n",
    "        tgt = tgt.unsqueeze(0).to(device)\n",
    "        generated = torch.randint(2, len(vocab), tgt.shape, device=device)\n",
    "        for step in range(steps):\n",
    "            mask = (generated == vocab['<PAD>'])\n",
    "            with torch.no_grad():\n",
    "                outputs = model(generated, src_key_padding_mask=mask)\n",
    "                predicted = outputs.argmax(dim=-1)\n",
    "            prob = 1.0 - (step + 1) / steps\n",
    "            random_mask = (torch.rand_like(generated.float()) < prob)\n",
    "            generated[random_mask] = predicted[random_mask]\n",
    "        mask = (tgt != vocab['<PAD>'])\n",
    "        total += mask.sum().item()\n",
    "        correct += ((generated == tgt) & mask).sum().item()\n",
    "    accuracy = correct / total if total > 0 else 0.0\n",
    "    print(f\"Test doğruluğu: {accuracy:.2%} ({correct}/{total})\")\n",
    "\n",
    "# Test et\n",
    "evaluate_diffusion_model(model, dataset, n_samples=100, steps=8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
